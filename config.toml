# RecRAG Configuration
# All non-sensitive configuration values

[embedding]
provider = "openai"
model = "text-embedding-3-small"
base_url = ""
# truncate = "NONE"  # Optional: NONE (default), START, END

# NVIDIA NIM example:
# provider = "nim"
# model = "nvidia/nv-embedqa-e5-v5"
# base_url = "https://integrate.api.nvidia.com/v1"

# Ollama example:
# provider = "ollama"
# model = "nomic-embed-text"
# base_url = "http://localhost:11434"

[llm]
provider = "openai"
model = "gpt-4o-mini"
base_url = ""

# NVIDIA NIM example:
# provider = "nim"
# model = "meta/llama-3.1-8b-instruct"
# base_url = "https://integrate.api.nvidia.com/v1"

# Ollama example:
# provider = "ollama"
# model = "llama3"
# base_url = "http://localhost:11434"

[ingestion]
directory = "data/pdfs"
chunk_size = 1024
chunk_overlap = 50

[retrieval]
top_k = 4
max_context_tokens = 4096
context_template = """Context information:
{context}

Question: {question}

Answer:"""

[storage]
directory = "storage"
